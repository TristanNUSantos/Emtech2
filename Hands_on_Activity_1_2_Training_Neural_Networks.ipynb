{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TristanNUSantos/Emtech2/blob/main/Hands_on_Activity_1_2_Training_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks\n",
        "\n",
        "Name: Santos Tristan Neal U.\n",
        "Section: CPE32S9"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a393fb4-75cb-470f-84cf-007297446521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/Emtech2/csv/pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "undefined-inventory",
      "metadata": {
        "id": "undefined-inventory",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "f02d298a-e389-463f-e6ad-ea5bf454898d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "646               1                     167              74              17   \n",
              "260               3                     191              68              15   \n",
              "510              12                      84              72              31   \n",
              "74                1                      79              75              30   \n",
              "632               2                     111              60               0   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "646      144  23.4              0.447   33             1  \n",
              "260      130  30.9              0.299   34             0  \n",
              "510        0  29.7              0.297   46             1  \n",
              "74         0  32.0              0.396   22             0  \n",
              "632        0  26.2              0.343   23             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b1a6b11-ea22-4a23-8cc9-1cefce3c0b4d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>646</th>\n",
              "      <td>1</td>\n",
              "      <td>167</td>\n",
              "      <td>74</td>\n",
              "      <td>17</td>\n",
              "      <td>144</td>\n",
              "      <td>23.4</td>\n",
              "      <td>0.447</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>3</td>\n",
              "      <td>191</td>\n",
              "      <td>68</td>\n",
              "      <td>15</td>\n",
              "      <td>130</td>\n",
              "      <td>30.9</td>\n",
              "      <td>0.299</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>12</td>\n",
              "      <td>84</td>\n",
              "      <td>72</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>29.7</td>\n",
              "      <td>0.297</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>1</td>\n",
              "      <td>79</td>\n",
              "      <td>75</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.396</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>2</td>\n",
              "      <td>111</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.343</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b1a6b11-ea22-4a23-8cc9-1cefce3c0b4d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b1a6b11-ea22-4a23-8cc9-1cefce3c0b4d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b1a6b11-ea22-4a23-8cc9-1cefce3c0b4d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-20d02060-0677-4783-805b-3c9b3259a50a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20d02060-0677-4783-805b-3c9b3259a50a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-20d02060-0677-4783-805b-3c9b3259a50a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"diabetes_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"times_pregnant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"glucose_tolerance_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50,\n        \"min\": 79,\n        \"max\": 191,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          191,\n          111,\n          84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 60,\n        \"max\": 75,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          68,\n          60,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skin_thickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 0,\n        \"max\": 31,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          15,\n          0,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 75,\n        \"min\": 0,\n        \"max\": 144,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          144,\n          130,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.561319980007413,\n        \"min\": 23.4,\n        \"max\": 32.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          30.9,\n          26.2,\n          29.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pedigree_function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06476727568764956,\n        \"min\": 0.297,\n        \"max\": 0.447,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.299,\n          0.343,\n          0.297\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 22,\n        \"max\": 46,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          34,\n          23,\n          46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "systematic-motorcycle",
      "metadata": {
        "id": "systematic-motorcycle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1485a9ac-4ff2-4fef-fe92-9f0e394fedf5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acceptable-equity",
      "metadata": {
        "id": "acceptable-equity",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307e8fd6-df56-4079-d711-08face537a69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correct-kingdom",
      "metadata": {
        "id": "correct-kingdom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adfeb066-85ec-41c3-d206-b4206bb949fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 12)                108       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "happy-prompt",
      "metadata": {
        "id": "happy-prompt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42986fec-98d7-49d1-fa84-426673443c7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 2s 12ms/step - loss: 0.7329 - accuracy: 0.6389 - val_loss: 0.7826 - val_accuracy: 0.5833\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7099 - accuracy: 0.6441 - val_loss: 0.7590 - val_accuracy: 0.5885\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6897 - accuracy: 0.6510 - val_loss: 0.7384 - val_accuracy: 0.5729\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.6528 - val_loss: 0.7201 - val_accuracy: 0.5938\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.6562 - val_loss: 0.7039 - val_accuracy: 0.5885\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6684 - val_loss: 0.6892 - val_accuracy: 0.6042\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.6684 - val_loss: 0.6761 - val_accuracy: 0.5990\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.6771 - val_loss: 0.6644 - val_accuracy: 0.6094\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6858 - val_loss: 0.6536 - val_accuracy: 0.6250\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.6892 - val_loss: 0.6438 - val_accuracy: 0.6354\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.6944 - val_loss: 0.6346 - val_accuracy: 0.6510\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.6979 - val_loss: 0.6263 - val_accuracy: 0.6667\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7066 - val_loss: 0.6188 - val_accuracy: 0.6667\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.7101 - val_loss: 0.6119 - val_accuracy: 0.6719\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7118 - val_loss: 0.6056 - val_accuracy: 0.6875\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7101 - val_loss: 0.5997 - val_accuracy: 0.6823\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7101 - val_loss: 0.5942 - val_accuracy: 0.6927\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5462 - accuracy: 0.7135 - val_loss: 0.5891 - val_accuracy: 0.6927\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7153 - val_loss: 0.5843 - val_accuracy: 0.7188\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7188 - val_loss: 0.5799 - val_accuracy: 0.7188\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7170 - val_loss: 0.5758 - val_accuracy: 0.7188\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7222 - val_loss: 0.5721 - val_accuracy: 0.7240\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7222 - val_loss: 0.5684 - val_accuracy: 0.7188\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7240 - val_loss: 0.5650 - val_accuracy: 0.7188\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7257 - val_loss: 0.5618 - val_accuracy: 0.7188\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7257 - val_loss: 0.5588 - val_accuracy: 0.7240\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7274 - val_loss: 0.5560 - val_accuracy: 0.7292\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7292 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7326 - val_loss: 0.5510 - val_accuracy: 0.7344\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7309 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7309 - val_loss: 0.5465 - val_accuracy: 0.7292\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7326 - val_loss: 0.5445 - val_accuracy: 0.7292\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7344 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7378 - val_loss: 0.5408 - val_accuracy: 0.7240\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7413 - val_loss: 0.5391 - val_accuracy: 0.7240\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7431 - val_loss: 0.5375 - val_accuracy: 0.7240\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7431 - val_loss: 0.5360 - val_accuracy: 0.7240\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7431 - val_loss: 0.5345 - val_accuracy: 0.7240\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7448 - val_loss: 0.5330 - val_accuracy: 0.7135\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7465 - val_loss: 0.5316 - val_accuracy: 0.7135\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7465 - val_loss: 0.5302 - val_accuracy: 0.7083\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7500 - val_loss: 0.5290 - val_accuracy: 0.7083\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7500 - val_loss: 0.5278 - val_accuracy: 0.7083\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7483 - val_loss: 0.5267 - val_accuracy: 0.7083\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7517 - val_loss: 0.5256 - val_accuracy: 0.7083\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7500 - val_loss: 0.5246 - val_accuracy: 0.7083\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7500 - val_loss: 0.5235 - val_accuracy: 0.7083\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7517 - val_loss: 0.5224 - val_accuracy: 0.7083\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7552 - val_loss: 0.5213 - val_accuracy: 0.7135\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7535 - val_loss: 0.5203 - val_accuracy: 0.7135\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7552 - val_loss: 0.5193 - val_accuracy: 0.7083\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7552 - val_loss: 0.5183 - val_accuracy: 0.7083\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7587 - val_loss: 0.5174 - val_accuracy: 0.7083\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7587 - val_loss: 0.5165 - val_accuracy: 0.7083\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7587 - val_loss: 0.5156 - val_accuracy: 0.7031\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7622 - val_loss: 0.5149 - val_accuracy: 0.7031\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7622 - val_loss: 0.5141 - val_accuracy: 0.7083\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7622 - val_loss: 0.5134 - val_accuracy: 0.7135\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7604 - val_loss: 0.5127 - val_accuracy: 0.7135\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7656 - val_loss: 0.5120 - val_accuracy: 0.7240\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7674 - val_loss: 0.5114 - val_accuracy: 0.7240\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7674 - val_loss: 0.5109 - val_accuracy: 0.7240\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7674 - val_loss: 0.5103 - val_accuracy: 0.7240\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7674 - val_loss: 0.5097 - val_accuracy: 0.7240\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7674 - val_loss: 0.5092 - val_accuracy: 0.7292\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7674 - val_loss: 0.5086 - val_accuracy: 0.7292\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7708 - val_loss: 0.5081 - val_accuracy: 0.7292\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7708 - val_loss: 0.5076 - val_accuracy: 0.7292\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7708 - val_loss: 0.5071 - val_accuracy: 0.7292\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7743 - val_loss: 0.5067 - val_accuracy: 0.7292\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7726 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.5054 - val_accuracy: 0.7344\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7691 - val_loss: 0.5050 - val_accuracy: 0.7396\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7691 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7691 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7708 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7726 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7726 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.5022 - val_accuracy: 0.7448\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.5020 - val_accuracy: 0.7448\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7726 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7743 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7760 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7743 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7760 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7743 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7760 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7778 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7760 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7743 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7726 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7726 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7760 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4541 - accuracy: 0.7760 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7743 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.7760 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4533 - accuracy: 0.7743 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.7708 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7726 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7760 - val_loss: 0.4976 - val_accuracy: 0.7656\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7778 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7795 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7795 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7778 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7743 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4502 - accuracy: 0.7778 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4499 - accuracy: 0.7760 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4496 - accuracy: 0.7778 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.7778 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7778 - val_loss: 0.4956 - val_accuracy: 0.7760\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7778 - val_loss: 0.4954 - val_accuracy: 0.7760\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.7760 - val_loss: 0.4953 - val_accuracy: 0.7760\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7760 - val_loss: 0.4953 - val_accuracy: 0.7760\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7760 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7760 - val_loss: 0.4951 - val_accuracy: 0.7760\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7760 - val_loss: 0.4951 - val_accuracy: 0.7760\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.4950 - val_accuracy: 0.7760\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7760 - val_loss: 0.4950 - val_accuracy: 0.7760\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7778 - val_loss: 0.4950 - val_accuracy: 0.7760\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7760 - val_loss: 0.4949 - val_accuracy: 0.7760\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7778 - val_loss: 0.4949 - val_accuracy: 0.7760\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7760 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7760 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7778 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7778 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7760 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7778 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7778 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7795 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7795 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7778 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7795 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7812 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7812 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7830 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7830 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7812 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7830 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7830 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7812 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7847 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7847 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7830 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7830 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7830 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7830 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7847 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7830 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7830 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7830 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7830 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7812\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7830 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7830 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7830 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7830 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7830 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7795 - val_loss: 0.4946 - val_accuracy: 0.7760\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7778 - val_loss: 0.4946 - val_accuracy: 0.7760\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7795 - val_loss: 0.4946 - val_accuracy: 0.7760\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7778 - val_loss: 0.4947 - val_accuracy: 0.7760\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7795 - val_loss: 0.4946 - val_accuracy: 0.7760\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.4947 - val_accuracy: 0.7760\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7778 - val_loss: 0.4947 - val_accuracy: 0.7760\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7778 - val_loss: 0.4947 - val_accuracy: 0.7760\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7778 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7795 - val_loss: 0.4947 - val_accuracy: 0.7760\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7795 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7760\n"
          ]
        }
      ],
      "source": [
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unsigned-nevada",
      "metadata": {
        "id": "unsigned-nevada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "035ec86d-21e4-44d3-a68b-17a79ff0f6aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_class_nn_1 =(model.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tough-catering",
      "metadata": {
        "id": "tough-catering",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f994f943-8c03-44a4-cfb2-fe68910baafe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "combined-zimbabwe",
      "metadata": {
        "id": "combined-zimbabwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc62d27c-2a6f-48e0-f65b-f592d41c3e87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.57696533],\n",
              "       [0.61074233],\n",
              "       [0.35749418],\n",
              "       [0.25565723],\n",
              "       [0.16068557],\n",
              "       [0.47349155],\n",
              "       [0.01845897],\n",
              "       [0.43593693],\n",
              "       [0.917828  ],\n",
              "       [0.16583294]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eleven-nebraska",
      "metadata": {
        "id": "eleven-nebraska",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "outputId": "ab2a87f7-6bf5-47ae-f3ba-274528c5dade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.776\n",
            "roc-auc is 0.817\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hidden-physics",
      "metadata": {
        "id": "hidden-physics",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c22eef-cecc-4210-ef60-9ad93621a0b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ],
      "source": [
        "run_hist.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "vRmMV6v4EvJ5",
        "outputId": "d0547ec1-4c6f-4cb3-b970-0eb4a8a4206e"
      },
      "id": "vRmMV6v4EvJ5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7d12d732d7e0>"
            ]
          },
          "metadata": {},
          "execution_count": 164
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "german-cherry",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "The graph showcase the curve each are on a diagonal line with the first part on the top before descending as it goes forward, which indicate that the prediction of this model are good. The 2nd graph indicates the train loss decrease, which proves that the validation is the same despite a different graph design."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "winedf = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Emtech2/csv/WineQT.csv\")"
      ],
      "metadata": {
        "id": "zDC-BbumCAk8"
      },
      "id": "zDC-BbumCAk8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "winedf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "DCzt7yi7EyKc",
        "outputId": "7ac70c04-f871-461f-f3b2-85f3b6e74b35"
      },
      "id": "DCzt7yi7EyKc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0               7.4             0.700         0.00             1.9      0.076   \n",
              "1               7.8             0.880         0.00             2.6      0.098   \n",
              "2               7.8             0.760         0.04             2.3      0.092   \n",
              "3              11.2             0.280         0.56             1.9      0.075   \n",
              "4               7.4             0.700         0.00             1.9      0.076   \n",
              "...             ...               ...          ...             ...        ...   \n",
              "1138            6.3             0.510         0.13             2.3      0.076   \n",
              "1139            6.8             0.620         0.08             1.9      0.068   \n",
              "1140            6.2             0.600         0.08             2.0      0.090   \n",
              "1141            5.9             0.550         0.10             2.2      0.062   \n",
              "1142            5.9             0.645         0.12             2.0      0.075   \n",
              "\n",
              "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
              "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
              "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
              "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
              "...                   ...                   ...      ...   ...        ...   \n",
              "1138                 29.0                  40.0  0.99574  3.42       0.75   \n",
              "1139                 28.0                  38.0  0.99651  3.42       0.82   \n",
              "1140                 32.0                  44.0  0.99490  3.45       0.58   \n",
              "1141                 39.0                  51.0  0.99512  3.52       0.76   \n",
              "1142                 32.0                  44.0  0.99547  3.57       0.71   \n",
              "\n",
              "      alcohol  quality    Id  \n",
              "0         9.4        5     0  \n",
              "1         9.8        5     1  \n",
              "2         9.8        5     2  \n",
              "3         9.8        6     3  \n",
              "4         9.4        5     4  \n",
              "...       ...      ...   ...  \n",
              "1138     11.0        6  1592  \n",
              "1139      9.5        6  1593  \n",
              "1140     10.5        5  1594  \n",
              "1141     11.2        6  1595  \n",
              "1142     10.2        5  1597  \n",
              "\n",
              "[1143 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ab37411-e950-4902-9dfe-88ce0817d042\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1138</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.510</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.076</td>\n",
              "      <td>29.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.99574</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.75</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1139</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.620</td>\n",
              "      <td>0.08</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.068</td>\n",
              "      <td>28.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.99651</td>\n",
              "      <td>3.42</td>\n",
              "      <td>0.82</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6</td>\n",
              "      <td>1593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1140</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.090</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.45</td>\n",
              "      <td>0.58</td>\n",
              "      <td>10.5</td>\n",
              "      <td>5</td>\n",
              "      <td>1594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1141</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.062</td>\n",
              "      <td>39.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0.99512</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.76</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "      <td>1595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1142</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.645</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.075</td>\n",
              "      <td>32.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99547</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>10.2</td>\n",
              "      <td>5</td>\n",
              "      <td>1597</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1143 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ab37411-e950-4902-9dfe-88ce0817d042')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ab37411-e950-4902-9dfe-88ce0817d042 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ab37411-e950-4902-9dfe-88ce0817d042');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86746641-97fb-4d9e-950c-0e689af70140\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86746641-97fb-4d9e-950c-0e689af70140')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86746641-97fb-4d9e-950c-0e689af70140 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "winedf",
              "summary": "{\n  \"name\": \"winedf\",\n  \"rows\": 1143,\n  \"fields\": [\n    {\n      \"column\": \"fixed acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.74759501716954,\n        \"min\": 4.6,\n        \"max\": 15.9,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          9.7,\n          7.0,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatile acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1796331930225245,\n        \"min\": 0.12,\n        \"max\": 1.58,\n        \"num_unique_values\": 135,\n        \"samples\": [\n          0.715,\n          0.48,\n          0.92\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"citric acid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19668585234821898,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 77,\n        \"samples\": [\n          0.02,\n          0.19,\n          0.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"residual sugar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3559174666826799,\n        \"min\": 0.9,\n        \"max\": 15.5,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          4.0,\n          1.9,\n          7.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chlorides\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04726733795238057,\n        \"min\": 0.012,\n        \"max\": 0.611,\n        \"num_unique_values\": 131,\n        \"samples\": [\n          0.061,\n          0.119,\n          0.066\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"free sulfur dioxide\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.250486123430822,\n        \"min\": 1.0,\n        \"max\": 68.0,\n        \"num_unique_values\": 53,\n        \"samples\": [\n          30.0,\n          46.0,\n          40.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total sulfur dioxide\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.78213030734311,\n        \"min\": 6.0,\n        \"max\": 289.0,\n        \"num_unique_values\": 138,\n        \"samples\": [\n          70.0,\n          91.0,\n          71.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"density\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0019250671302545696,\n        \"min\": 0.99007,\n        \"max\": 1.00369,\n        \"num_unique_values\": 388,\n        \"samples\": [\n          0.99434,\n          0.9927,\n          0.99528\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15666405977275194,\n        \"min\": 2.74,\n        \"max\": 4.01,\n        \"num_unique_values\": 87,\n        \"samples\": [\n          2.92,\n          3.51,\n          3.44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sulphates\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1703987144670741,\n        \"min\": 0.33,\n        \"max\": 2.0,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          0.72,\n          1.61,\n          1.12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alcohol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0821956098764445,\n        \"min\": 8.4,\n        \"max\": 14.9,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          9.4,\n          9.9,\n          12.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 8,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5,\n          6,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 463,\n        \"min\": 0,\n        \"max\": 1597,\n        \"num_unique_values\": 1143,\n        \"samples\": [\n          222,\n          1514,\n          417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "winedf.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ul_EtMfE2s7",
        "outputId": "1939096d-580a-4f9e-e6b7-4a071b64d87b"
      },
      "id": "0ul_EtMfE2s7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fixed acidity           float64\n",
              "volatile acidity        float64\n",
              "citric acid             float64\n",
              "residual sugar          float64\n",
              "chlorides               float64\n",
              "free sulfur dioxide     float64\n",
              "total sulfur dioxide    float64\n",
              "density                 float64\n",
              "pH                      float64\n",
              "sulphates               float64\n",
              "alcohol                 float64\n",
              "quality                   int64\n",
              "Id                        int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Split the data into train and test (80%, 20%)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ],
      "metadata": {
        "id": "WQS-5kyEE_a-"
      },
      "id": "WQS-5kyEE_a-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y), np.mean(1-y)"
      ],
      "metadata": {
        "id": "qL4vphU8E_X2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d6370f-b429-472e-a6f1-08b934b49e31"
      },
      "id": "qL4vphU8E_X2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Normalize the data\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "metadata": {
        "id": "4Y5iz1QsLjD4"
      },
      "id": "4Y5iz1QsLjD4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model2 = Sequential([\n",
        "    Dense(10, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "UcFWyaRBE_G0"
      },
      "id": "UcFWyaRBE_G0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SV1YeUXLuIZ",
        "outputId": "f972859d-677d-4e2d-c4b0-e9c96ac8d9fe"
      },
      "id": "4SV1YeUXLuIZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_26 (Dense)            (None, 10)                90        \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103 (412.00 Byte)\n",
            "Trainable params: 103 (412.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist2 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f4ruMmsTDBt",
        "outputId": "baaaeb19-26f4-46a3-fb2d-f63dd7550a08"
      },
      "id": "-f4ruMmsTDBt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4371 - accuracy: 0.7795 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.7795 - val_loss: 0.4949 - val_accuracy: 0.7760\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.4949 - val_accuracy: 0.7760\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.7812 - val_loss: 0.4950 - val_accuracy: 0.7760\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7795 - val_loss: 0.4950 - val_accuracy: 0.7760\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.7795 - val_loss: 0.4951 - val_accuracy: 0.7760\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7795 - val_loss: 0.4951 - val_accuracy: 0.7760\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.4951 - val_accuracy: 0.7760\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.4951 - val_accuracy: 0.7760\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4360 - accuracy: 0.7830 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.7812 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4358 - accuracy: 0.7812 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.4953 - val_accuracy: 0.7760\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7812 - val_loss: 0.4954 - val_accuracy: 0.7760\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.4954 - val_accuracy: 0.7760\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.4954 - val_accuracy: 0.7760\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.4954 - val_accuracy: 0.7760\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.4956 - val_accuracy: 0.7760\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7865 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7882 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.4967 - val_accuracy: 0.7760\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.4967 - val_accuracy: 0.7760\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.4967 - val_accuracy: 0.7760\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.4967 - val_accuracy: 0.7760\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4968 - val_accuracy: 0.7812\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.4970 - val_accuracy: 0.7812\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4971 - val_accuracy: 0.7812\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4306 - accuracy: 0.7882 - val_loss: 0.4971 - val_accuracy: 0.7812\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.4972 - val_accuracy: 0.7812\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7812\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.4973 - val_accuracy: 0.7812\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.4973 - val_accuracy: 0.7812\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.4974 - val_accuracy: 0.7812\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.4974 - val_accuracy: 0.7812\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.4975 - val_accuracy: 0.7812\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.4975 - val_accuracy: 0.7812\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.7865 - val_loss: 0.4976 - val_accuracy: 0.7812\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7812\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.4976 - val_accuracy: 0.7812\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.4975 - val_accuracy: 0.7812\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.4976 - val_accuracy: 0.7812\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.4976 - val_accuracy: 0.7812\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7812\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.4977 - val_accuracy: 0.7812\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.7847 - val_loss: 0.4978 - val_accuracy: 0.7812\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7812\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7812\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.4978 - val_accuracy: 0.7812\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7812\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.4980 - val_accuracy: 0.7812\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.4980 - val_accuracy: 0.7812\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.4980 - val_accuracy: 0.7812\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4287 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4284 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7812\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.4982 - val_accuracy: 0.7812\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.4982 - val_accuracy: 0.7812\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.4983 - val_accuracy: 0.7812\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.4984 - val_accuracy: 0.7812\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.4985 - val_accuracy: 0.7812\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.4985 - val_accuracy: 0.7812\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.4985 - val_accuracy: 0.7812\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.4985 - val_accuracy: 0.7812\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.4986 - val_accuracy: 0.7812\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.4986 - val_accuracy: 0.7812\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4278 - accuracy: 0.7865 - val_loss: 0.4987 - val_accuracy: 0.7812\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4276 - accuracy: 0.7865 - val_loss: 0.4987 - val_accuracy: 0.7812\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.4988 - val_accuracy: 0.7812\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.4988 - val_accuracy: 0.7812\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.4988 - val_accuracy: 0.7812\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.4989 - val_accuracy: 0.7812\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.4989 - val_accuracy: 0.7812\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.4990 - val_accuracy: 0.7812\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.4991 - val_accuracy: 0.7812\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.7865 - val_loss: 0.4992 - val_accuracy: 0.7812\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.4993 - val_accuracy: 0.7760\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.4993 - val_accuracy: 0.7760\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.4993 - val_accuracy: 0.7760\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4267 - accuracy: 0.7865 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4265 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4264 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4264 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4262 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4260 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4260 - accuracy: 0.7882 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4260 - accuracy: 0.7882 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4258 - accuracy: 0.7899 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4257 - accuracy: 0.7882 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4252 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7917 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7917 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7934 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7934 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7917 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7604\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7934 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7604\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7969 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8003 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8003 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7951 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.8003 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8003 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.8003 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8003 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8021 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8021 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8021 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8021 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8021 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8021 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8021 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8038 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8021 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8021 - val_loss: 0.5053 - val_accuracy: 0.7708\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8021 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5058 - val_accuracy: 0.7708\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8021 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8038 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8021 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8021 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8038 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4176 - accuracy: 0.8038 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7708\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8021 - val_loss: 0.5062 - val_accuracy: 0.7708\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8038 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.8021 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.8021 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.8038 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.7986 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.7986 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8038 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8021 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7760\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8038 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8038 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8021 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7708\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5082 - val_accuracy: 0.7708\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8038 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7708\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8038 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8003 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8003 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8003 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8003 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8003 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8003 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8003 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8003 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8021 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8056 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8056 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8003 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8003 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8003 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8056 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8003 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8021 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8003 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8021 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8021 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8021 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8021 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5105 - val_accuracy: 0.7656\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8003 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8021 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8021 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5108 - val_accuracy: 0.7656\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8056 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8021 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8021 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8021 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8056 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8038 - val_loss: 0.5113 - val_accuracy: 0.7708\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8021 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8021 - val_loss: 0.5113 - val_accuracy: 0.7708\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8021 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8073 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8090 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8056 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8073 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8073 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8073 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8073 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8090 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8073 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8073 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8038 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8090 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8073 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8090 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8073 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8073 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8090 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8073 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8056 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8073 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8090 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8056 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8073 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8056 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8090 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8056 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8056 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8056 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8073 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8090 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8073 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8038 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8090 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8056 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8090 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8090 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8090 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8090 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8073 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8073 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8090 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8108 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8108 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5161 - val_accuracy: 0.7604\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8125 - val_loss: 0.5162 - val_accuracy: 0.7604\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8090 - val_loss: 0.5162 - val_accuracy: 0.7604\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5163 - val_accuracy: 0.7604\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5164 - val_accuracy: 0.7604\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4111 - accuracy: 0.8108 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8125 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8125 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5167 - val_accuracy: 0.7604\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8125 - val_loss: 0.5166 - val_accuracy: 0.7604\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8125 - val_loss: 0.5167 - val_accuracy: 0.7604\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8125 - val_loss: 0.5168 - val_accuracy: 0.7604\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8125 - val_loss: 0.5169 - val_accuracy: 0.7604\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8142 - val_loss: 0.5169 - val_accuracy: 0.7604\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8108 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8108 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8142 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8125 - val_loss: 0.5173 - val_accuracy: 0.7552\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8125 - val_loss: 0.5173 - val_accuracy: 0.7552\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8125 - val_loss: 0.5175 - val_accuracy: 0.7552\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8142 - val_loss: 0.5175 - val_accuracy: 0.7552\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8125 - val_loss: 0.5174 - val_accuracy: 0.7552\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8125 - val_loss: 0.5176 - val_accuracy: 0.7552\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8125 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8125 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8125 - val_loss: 0.5176 - val_accuracy: 0.7552\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8160 - val_loss: 0.5178 - val_accuracy: 0.7552\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8160 - val_loss: 0.5178 - val_accuracy: 0.7552\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8142 - val_loss: 0.5178 - val_accuracy: 0.7552\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8160 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4102 - accuracy: 0.8142 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4102 - accuracy: 0.8160 - val_loss: 0.5180 - val_accuracy: 0.7552\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4101 - accuracy: 0.8142 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4100 - accuracy: 0.8160 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4101 - accuracy: 0.8142 - val_loss: 0.5183 - val_accuracy: 0.7552\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8142 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8160 - val_loss: 0.5184 - val_accuracy: 0.7552\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8142 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8160 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8142 - val_loss: 0.5186 - val_accuracy: 0.7552\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8160 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8142 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8142 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8160 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8142 - val_loss: 0.5188 - val_accuracy: 0.7552\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8142 - val_loss: 0.5189 - val_accuracy: 0.7552\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8160 - val_loss: 0.5190 - val_accuracy: 0.7552\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8142 - val_loss: 0.5190 - val_accuracy: 0.7552\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8142 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8142 - val_loss: 0.5192 - val_accuracy: 0.7552\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8160 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8142 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8142 - val_loss: 0.5192 - val_accuracy: 0.7552\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8142 - val_loss: 0.5193 - val_accuracy: 0.7552\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8160 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8160 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8142 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8142 - val_loss: 0.5195 - val_accuracy: 0.7552\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8160 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8142 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8160 - val_loss: 0.5197 - val_accuracy: 0.7552\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8142 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8142 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8142 - val_loss: 0.5200 - val_accuracy: 0.7552\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8160 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8142 - val_loss: 0.5202 - val_accuracy: 0.7552\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8160 - val_loss: 0.5202 - val_accuracy: 0.7552\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8142 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8160 - val_loss: 0.5204 - val_accuracy: 0.7552\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5203 - val_accuracy: 0.7552\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8142 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8160 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8160 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8142 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8142 - val_loss: 0.5207 - val_accuracy: 0.7604\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5207 - val_accuracy: 0.7552\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8142 - val_loss: 0.5208 - val_accuracy: 0.7552\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8142 - val_loss: 0.5208 - val_accuracy: 0.7604\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8142 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.5210 - val_accuracy: 0.7604\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8142 - val_loss: 0.5211 - val_accuracy: 0.7604\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8142 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8142 - val_loss: 0.5212 - val_accuracy: 0.7604\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8160 - val_loss: 0.5213 - val_accuracy: 0.7656\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8160 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8142 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8160 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8160 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8160 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8177 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8177 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8160 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8160 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8160 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8160 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8160 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8177 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8160 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8177 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8160 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8160 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8160 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8177 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8160 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8160 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8160 - val_loss: 0.5221 - val_accuracy: 0.7604\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8160 - val_loss: 0.5222 - val_accuracy: 0.7604\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8160 - val_loss: 0.5223 - val_accuracy: 0.7604\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8160 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8177 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8160 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8177 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8160 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8177 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8194 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8177 - val_loss: 0.5226 - val_accuracy: 0.7604\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8177 - val_loss: 0.5225 - val_accuracy: 0.7604\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8177 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8177 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8177 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8177 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8160 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8194 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8177 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8177 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8194 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8177 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8194 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8177 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8177 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8177 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8177 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8177 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8194 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8177 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8177 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8194 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8177 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8160 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8177 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8160 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8194 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.8177 - val_loss: 0.5246 - val_accuracy: 0.7604\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4060 - accuracy: 0.8160 - val_loss: 0.5246 - val_accuracy: 0.7604\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8160 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8177 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8177 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8177 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8194 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8177 - val_loss: 0.5250 - val_accuracy: 0.7656\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4058 - accuracy: 0.8194 - val_loss: 0.5250 - val_accuracy: 0.7656\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8160 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8212 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8160 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8177 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4058 - accuracy: 0.8160 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8177 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8160 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8160 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8177 - val_loss: 0.5256 - val_accuracy: 0.7656\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8177 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8160 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4055 - accuracy: 0.8160 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8177 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4054 - accuracy: 0.8177 - val_loss: 0.5260 - val_accuracy: 0.7656\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4054 - accuracy: 0.8160 - val_loss: 0.5260 - val_accuracy: 0.7656\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8177 - val_loss: 0.5261 - val_accuracy: 0.7656\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4054 - accuracy: 0.8160 - val_loss: 0.5261 - val_accuracy: 0.7656\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8160 - val_loss: 0.5262 - val_accuracy: 0.7656\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8160 - val_loss: 0.5263 - val_accuracy: 0.7656\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8160 - val_loss: 0.5263 - val_accuracy: 0.7656\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8177 - val_loss: 0.5264 - val_accuracy: 0.7656\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8177 - val_loss: 0.5264 - val_accuracy: 0.7656\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.8177 - val_loss: 0.5265 - val_accuracy: 0.7656\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.8177 - val_loss: 0.5266 - val_accuracy: 0.7656\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8194 - val_loss: 0.5267 - val_accuracy: 0.7656\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8177 - val_loss: 0.5267 - val_accuracy: 0.7656\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8177 - val_loss: 0.5267 - val_accuracy: 0.7656\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8194 - val_loss: 0.5268 - val_accuracy: 0.7656\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4052 - accuracy: 0.8160 - val_loss: 0.5268 - val_accuracy: 0.7656\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8177 - val_loss: 0.5269 - val_accuracy: 0.7656\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8194 - val_loss: 0.5270 - val_accuracy: 0.7656\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8194 - val_loss: 0.5270 - val_accuracy: 0.7656\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8160 - val_loss: 0.5271 - val_accuracy: 0.7656\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8177 - val_loss: 0.5273 - val_accuracy: 0.7656\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8194 - val_loss: 0.5273 - val_accuracy: 0.7656\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8177 - val_loss: 0.5273 - val_accuracy: 0.7656\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8194 - val_loss: 0.5274 - val_accuracy: 0.7656\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8194 - val_loss: 0.5274 - val_accuracy: 0.7656\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8160 - val_loss: 0.5275 - val_accuracy: 0.7656\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8194 - val_loss: 0.5274 - val_accuracy: 0.7656\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8194 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8212 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8177 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8177 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8212 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8194 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8194 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8194 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8194 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8212 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8194 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8177 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8194 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8194 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8212 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8212 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8194 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8194 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8194 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8194 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8212 - val_loss: 0.5286 - val_accuracy: 0.7656\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8212 - val_loss: 0.5287 - val_accuracy: 0.7656\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8212 - val_loss: 0.5288 - val_accuracy: 0.7656\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8212 - val_loss: 0.5287 - val_accuracy: 0.7656\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8177 - val_loss: 0.5288 - val_accuracy: 0.7656\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8177 - val_loss: 0.5290 - val_accuracy: 0.7656\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8177 - val_loss: 0.5290 - val_accuracy: 0.7656\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8194 - val_loss: 0.5290 - val_accuracy: 0.7656\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8194 - val_loss: 0.5291 - val_accuracy: 0.7656\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8194 - val_loss: 0.5292 - val_accuracy: 0.7656\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8212 - val_loss: 0.5292 - val_accuracy: 0.7656\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8194 - val_loss: 0.5292 - val_accuracy: 0.7656\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8212 - val_loss: 0.5293 - val_accuracy: 0.7656\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8212 - val_loss: 0.5293 - val_accuracy: 0.7656\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8194 - val_loss: 0.5294 - val_accuracy: 0.7656\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8194 - val_loss: 0.5295 - val_accuracy: 0.7656\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8194 - val_loss: 0.5296 - val_accuracy: 0.7656\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8194 - val_loss: 0.5295 - val_accuracy: 0.7656\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8194 - val_loss: 0.5295 - val_accuracy: 0.7656\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8194 - val_loss: 0.5295 - val_accuracy: 0.7656\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8194 - val_loss: 0.5296 - val_accuracy: 0.7656\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8194 - val_loss: 0.5297 - val_accuracy: 0.7656\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8194 - val_loss: 0.5297 - val_accuracy: 0.7656\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8212 - val_loss: 0.5297 - val_accuracy: 0.7656\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8212 - val_loss: 0.5296 - val_accuracy: 0.7656\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8194 - val_loss: 0.5297 - val_accuracy: 0.7656\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8194 - val_loss: 0.5298 - val_accuracy: 0.7656\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8194 - val_loss: 0.5299 - val_accuracy: 0.7656\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8212 - val_loss: 0.5300 - val_accuracy: 0.7656\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4038 - accuracy: 0.8194 - val_loss: 0.5300 - val_accuracy: 0.7656\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4038 - accuracy: 0.8194 - val_loss: 0.5300 - val_accuracy: 0.7656\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4038 - accuracy: 0.8194 - val_loss: 0.5300 - val_accuracy: 0.7656\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8194 - val_loss: 0.5302 - val_accuracy: 0.7656\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8212 - val_loss: 0.5302 - val_accuracy: 0.7656\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.8194 - val_loss: 0.5302 - val_accuracy: 0.7656\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8194 - val_loss: 0.5303 - val_accuracy: 0.7656\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8194 - val_loss: 0.5304 - val_accuracy: 0.7656\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8194 - val_loss: 0.5303 - val_accuracy: 0.7656\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8194 - val_loss: 0.5304 - val_accuracy: 0.7656\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8194 - val_loss: 0.5303 - val_accuracy: 0.7656\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8194 - val_loss: 0.5304 - val_accuracy: 0.7656\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8212 - val_loss: 0.5304 - val_accuracy: 0.7656\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8194 - val_loss: 0.5305 - val_accuracy: 0.7656\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8212 - val_loss: 0.5306 - val_accuracy: 0.7656\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8194 - val_loss: 0.5307 - val_accuracy: 0.7656\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8212 - val_loss: 0.5307 - val_accuracy: 0.7656\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8212 - val_loss: 0.5307 - val_accuracy: 0.7656\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8194 - val_loss: 0.5308 - val_accuracy: 0.7656\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8212 - val_loss: 0.5308 - val_accuracy: 0.7656\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8212 - val_loss: 0.5308 - val_accuracy: 0.7656\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8194 - val_loss: 0.5310 - val_accuracy: 0.7656\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8194 - val_loss: 0.5310 - val_accuracy: 0.7656\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8212 - val_loss: 0.5310 - val_accuracy: 0.7656\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8212 - val_loss: 0.5311 - val_accuracy: 0.7656\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8212 - val_loss: 0.5312 - val_accuracy: 0.7656\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8212 - val_loss: 0.5312 - val_accuracy: 0.7656\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8212 - val_loss: 0.5313 - val_accuracy: 0.7656\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8212 - val_loss: 0.5313 - val_accuracy: 0.7656\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8212 - val_loss: 0.5314 - val_accuracy: 0.7656\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8194 - val_loss: 0.5314 - val_accuracy: 0.7656\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8212 - val_loss: 0.5314 - val_accuracy: 0.7656\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8194 - val_loss: 0.5314 - val_accuracy: 0.7656\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8194 - val_loss: 0.5314 - val_accuracy: 0.7656\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8212 - val_loss: 0.5315 - val_accuracy: 0.7656\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8212 - val_loss: 0.5315 - val_accuracy: 0.7656\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8194 - val_loss: 0.5315 - val_accuracy: 0.7656\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8212 - val_loss: 0.5316 - val_accuracy: 0.7656\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8212 - val_loss: 0.5317 - val_accuracy: 0.7656\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8229 - val_loss: 0.5318 - val_accuracy: 0.7656\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8247 - val_loss: 0.5319 - val_accuracy: 0.7656\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8194 - val_loss: 0.5319 - val_accuracy: 0.7656\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8212 - val_loss: 0.5319 - val_accuracy: 0.7656\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8212 - val_loss: 0.5319 - val_accuracy: 0.7656\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8229 - val_loss: 0.5320 - val_accuracy: 0.7656\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8212 - val_loss: 0.5320 - val_accuracy: 0.7656\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8229 - val_loss: 0.5321 - val_accuracy: 0.7656\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8229 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8229 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8212 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8247 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8229 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4029 - accuracy: 0.8212 - val_loss: 0.5323 - val_accuracy: 0.7656\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4030 - accuracy: 0.8229 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8229 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.8247 - val_loss: 0.5327 - val_accuracy: 0.7656\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4030 - accuracy: 0.8247 - val_loss: 0.5326 - val_accuracy: 0.7656\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8247 - val_loss: 0.5326 - val_accuracy: 0.7656\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4030 - accuracy: 0.8212 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8229 - val_loss: 0.5327 - val_accuracy: 0.7656\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8247 - val_loss: 0.5327 - val_accuracy: 0.7656\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8247 - val_loss: 0.5327 - val_accuracy: 0.7656\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8212 - val_loss: 0.5328 - val_accuracy: 0.7656\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4027 - accuracy: 0.8212 - val_loss: 0.5329 - val_accuracy: 0.7656\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4027 - accuracy: 0.8229 - val_loss: 0.5328 - val_accuracy: 0.7604\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8229 - val_loss: 0.5328 - val_accuracy: 0.7552\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4027 - accuracy: 0.8229 - val_loss: 0.5328 - val_accuracy: 0.7552\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8229 - val_loss: 0.5329 - val_accuracy: 0.7552\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8229 - val_loss: 0.5329 - val_accuracy: 0.7552\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8229 - val_loss: 0.5330 - val_accuracy: 0.7552\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8229 - val_loss: 0.5331 - val_accuracy: 0.7552\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8247 - val_loss: 0.5331 - val_accuracy: 0.7552\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8247 - val_loss: 0.5332 - val_accuracy: 0.7552\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8229 - val_loss: 0.5332 - val_accuracy: 0.7552\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.5333 - val_accuracy: 0.7552\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8229 - val_loss: 0.5333 - val_accuracy: 0.7552\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.5334 - val_accuracy: 0.7552\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8229 - val_loss: 0.5334 - val_accuracy: 0.7552\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.5335 - val_accuracy: 0.7552\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.5336 - val_accuracy: 0.7552\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.8247 - val_loss: 0.5336 - val_accuracy: 0.7552\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8247 - val_loss: 0.5336 - val_accuracy: 0.7552\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.5338 - val_accuracy: 0.7552\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4024 - accuracy: 0.8229 - val_loss: 0.5337 - val_accuracy: 0.7552\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8247 - val_loss: 0.5337 - val_accuracy: 0.7552\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4025 - accuracy: 0.8229 - val_loss: 0.5338 - val_accuracy: 0.7552\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4025 - accuracy: 0.8229 - val_loss: 0.5338 - val_accuracy: 0.7552\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.4025 - accuracy: 0.8247 - val_loss: 0.5339 - val_accuracy: 0.7552\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.5340 - val_accuracy: 0.7552\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8229 - val_loss: 0.5339 - val_accuracy: 0.7552\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8229 - val_loss: 0.5340 - val_accuracy: 0.7552\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8264 - val_loss: 0.5340 - val_accuracy: 0.7552\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8247 - val_loss: 0.5341 - val_accuracy: 0.7552\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8247 - val_loss: 0.5341 - val_accuracy: 0.7552\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8247 - val_loss: 0.5341 - val_accuracy: 0.7552\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8247 - val_loss: 0.5342 - val_accuracy: 0.7552\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8247 - val_loss: 0.5342 - val_accuracy: 0.7552\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8229 - val_loss: 0.5342 - val_accuracy: 0.7552\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8264 - val_loss: 0.5343 - val_accuracy: 0.7552\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8247 - val_loss: 0.5343 - val_accuracy: 0.7552\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8229 - val_loss: 0.5344 - val_accuracy: 0.7552\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8264 - val_loss: 0.5344 - val_accuracy: 0.7552\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8264 - val_loss: 0.5344 - val_accuracy: 0.7552\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8264 - val_loss: 0.5345 - val_accuracy: 0.7552\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8247 - val_loss: 0.5345 - val_accuracy: 0.7552\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8264 - val_loss: 0.5345 - val_accuracy: 0.7552\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8247 - val_loss: 0.5346 - val_accuracy: 0.7552\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8264 - val_loss: 0.5346 - val_accuracy: 0.7552\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8264 - val_loss: 0.5347 - val_accuracy: 0.7552\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8264 - val_loss: 0.5348 - val_accuracy: 0.7552\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8247 - val_loss: 0.5348 - val_accuracy: 0.7552\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8264 - val_loss: 0.5350 - val_accuracy: 0.7552\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8264 - val_loss: 0.5351 - val_accuracy: 0.7552\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8264 - val_loss: 0.5350 - val_accuracy: 0.7552\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8264 - val_loss: 0.5349 - val_accuracy: 0.7552\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8264 - val_loss: 0.5351 - val_accuracy: 0.7552\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8264 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8264 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8264 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8264 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8247 - val_loss: 0.5353 - val_accuracy: 0.7552\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8264 - val_loss: 0.5353 - val_accuracy: 0.7552\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8264 - val_loss: 0.5353 - val_accuracy: 0.7552\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8264 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8264 - val_loss: 0.5353 - val_accuracy: 0.7552\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8264 - val_loss: 0.5355 - val_accuracy: 0.7552\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8264 - val_loss: 0.5356 - val_accuracy: 0.7552\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8264 - val_loss: 0.5356 - val_accuracy: 0.7552\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8264 - val_loss: 0.5357 - val_accuracy: 0.7552\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8264 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8264 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8264 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8264 - val_loss: 0.5359 - val_accuracy: 0.7552\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8247 - val_loss: 0.5359 - val_accuracy: 0.7552\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8264 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8264 - val_loss: 0.5361 - val_accuracy: 0.7552\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8299 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8281 - val_loss: 0.5362 - val_accuracy: 0.7552\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8264 - val_loss: 0.5362 - val_accuracy: 0.7552\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8264 - val_loss: 0.5363 - val_accuracy: 0.7552\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8264 - val_loss: 0.5363 - val_accuracy: 0.7552\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8247 - val_loss: 0.5363 - val_accuracy: 0.7552\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8264 - val_loss: 0.5363 - val_accuracy: 0.7552\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8264 - val_loss: 0.5364 - val_accuracy: 0.7552\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8281 - val_loss: 0.5365 - val_accuracy: 0.7552\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8281 - val_loss: 0.5365 - val_accuracy: 0.7552\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8264 - val_loss: 0.5366 - val_accuracy: 0.7552\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8264 - val_loss: 0.5365 - val_accuracy: 0.7552\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8264 - val_loss: 0.5366 - val_accuracy: 0.7552\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8281 - val_loss: 0.5366 - val_accuracy: 0.7552\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8299 - val_loss: 0.5366 - val_accuracy: 0.7552\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8281 - val_loss: 0.5367 - val_accuracy: 0.7552\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8264 - val_loss: 0.5367 - val_accuracy: 0.7552\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8281 - val_loss: 0.5368 - val_accuracy: 0.7552\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8299 - val_loss: 0.5369 - val_accuracy: 0.7552\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8299 - val_loss: 0.5369 - val_accuracy: 0.7552\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8299 - val_loss: 0.5370 - val_accuracy: 0.7552\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8299 - val_loss: 0.5370 - val_accuracy: 0.7552\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8299 - val_loss: 0.5369 - val_accuracy: 0.7552\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8299 - val_loss: 0.5370 - val_accuracy: 0.7552\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8281 - val_loss: 0.5371 - val_accuracy: 0.7552\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8299 - val_loss: 0.5371 - val_accuracy: 0.7552\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8299 - val_loss: 0.5372 - val_accuracy: 0.7552\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8299 - val_loss: 0.5372 - val_accuracy: 0.7552\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8281 - val_loss: 0.5373 - val_accuracy: 0.7552\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8281 - val_loss: 0.5373 - val_accuracy: 0.7552\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8281 - val_loss: 0.5374 - val_accuracy: 0.7552\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8281 - val_loss: 0.5374 - val_accuracy: 0.7552\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8281 - val_loss: 0.5374 - val_accuracy: 0.7552\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8299 - val_loss: 0.5375 - val_accuracy: 0.7552\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5375 - val_accuracy: 0.7552\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8299 - val_loss: 0.5376 - val_accuracy: 0.7552\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8299 - val_loss: 0.5376 - val_accuracy: 0.7552\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5375 - val_accuracy: 0.7552\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8299 - val_loss: 0.5375 - val_accuracy: 0.7552\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5375 - val_accuracy: 0.7552\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5375 - val_accuracy: 0.7552\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8299 - val_loss: 0.5376 - val_accuracy: 0.7552\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8299 - val_loss: 0.5377 - val_accuracy: 0.7552\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8281 - val_loss: 0.5378 - val_accuracy: 0.7552\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5379 - val_accuracy: 0.7552\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8281 - val_loss: 0.5379 - val_accuracy: 0.7552\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8299 - val_loss: 0.5379 - val_accuracy: 0.7552\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8299 - val_loss: 0.5379 - val_accuracy: 0.7552\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8299 - val_loss: 0.5380 - val_accuracy: 0.7552\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5379 - val_accuracy: 0.7552\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8299 - val_loss: 0.5380 - val_accuracy: 0.7552\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5381 - val_accuracy: 0.7552\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8299 - val_loss: 0.5381 - val_accuracy: 0.7552\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8281 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8299 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8299 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8299 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8299 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8299 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8281 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4008 - accuracy: 0.8281 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4008 - accuracy: 0.8281 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8281 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4008 - accuracy: 0.8281 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8299 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4007 - accuracy: 0.8281 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8281 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8281 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8281 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8281 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4007 - accuracy: 0.8281 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8281 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8281 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4005 - accuracy: 0.8281 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4005 - accuracy: 0.8281 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4005 - accuracy: 0.8281 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8281 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4005 - accuracy: 0.8281 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8281 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8281 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8281 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8281 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8281 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8281 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8281 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8281 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8281 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8281 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8281 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8281 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8281 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8281 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8281 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8281 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8281 - val_loss: 0.5409 - val_accuracy: 0.7552\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8281 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8281 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8299 - val_loss: 0.5409 - val_accuracy: 0.7552\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8281 - val_loss: 0.5409 - val_accuracy: 0.7552\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8281 - val_loss: 0.5408 - val_accuracy: 0.7552\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8281 - val_loss: 0.5409 - val_accuracy: 0.7552\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8281 - val_loss: 0.5410 - val_accuracy: 0.7552\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8281 - val_loss: 0.5410 - val_accuracy: 0.7552\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8281 - val_loss: 0.5412 - val_accuracy: 0.7552\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8281 - val_loss: 0.5412 - val_accuracy: 0.7552\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8281 - val_loss: 0.5412 - val_accuracy: 0.7552\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8281 - val_loss: 0.5412 - val_accuracy: 0.7552\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8281 - val_loss: 0.5413 - val_accuracy: 0.7552\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8281 - val_loss: 0.5413 - val_accuracy: 0.7552\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8281 - val_loss: 0.5413 - val_accuracy: 0.7552\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8281 - val_loss: 0.5415 - val_accuracy: 0.7552\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8281 - val_loss: 0.5414 - val_accuracy: 0.7552\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8299 - val_loss: 0.5414 - val_accuracy: 0.7552\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8264 - val_loss: 0.5416 - val_accuracy: 0.7552\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8299 - val_loss: 0.5416 - val_accuracy: 0.7552\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8247 - val_loss: 0.5417 - val_accuracy: 0.7552\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8281 - val_loss: 0.5417 - val_accuracy: 0.7552\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8316 - val_loss: 0.5416 - val_accuracy: 0.7552\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8264 - val_loss: 0.5417 - val_accuracy: 0.7552\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8299 - val_loss: 0.5418 - val_accuracy: 0.7552\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8264 - val_loss: 0.5419 - val_accuracy: 0.7552\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8281 - val_loss: 0.5418 - val_accuracy: 0.7552\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8247 - val_loss: 0.5419 - val_accuracy: 0.7552\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8264 - val_loss: 0.5420 - val_accuracy: 0.7552\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8316 - val_loss: 0.5420 - val_accuracy: 0.7552\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8264 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8281 - val_loss: 0.5420 - val_accuracy: 0.7552\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8281 - val_loss: 0.5420 - val_accuracy: 0.7552\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8264 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3997 - accuracy: 0.8264 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8264 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8281 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8281 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8264 - val_loss: 0.5423 - val_accuracy: 0.7552\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8264 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8264 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8264 - val_loss: 0.5425 - val_accuracy: 0.7552\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8264 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8264 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8264 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3997 - accuracy: 0.8264 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8264 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8264 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8264 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8299 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8264 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8264 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8264 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8281 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8264 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8264 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8264 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8264 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8281 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8281 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8264 - val_loss: 0.5433 - val_accuracy: 0.7552\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8264 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8281 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8281 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8264 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8264 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8281 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8281 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8264 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8264 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8281 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8264 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8281 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8264 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8281 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8264 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8281 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8281 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8264 - val_loss: 0.5439 - val_accuracy: 0.7448\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8281 - val_loss: 0.5439 - val_accuracy: 0.7448\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8264 - val_loss: 0.5440 - val_accuracy: 0.7448\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8281 - val_loss: 0.5438 - val_accuracy: 0.7448\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8264 - val_loss: 0.5439 - val_accuracy: 0.7448\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8281 - val_loss: 0.5438 - val_accuracy: 0.7448\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8264 - val_loss: 0.5440 - val_accuracy: 0.7448\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8281 - val_loss: 0.5440 - val_accuracy: 0.7448\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8264 - val_loss: 0.5440 - val_accuracy: 0.7448\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8281 - val_loss: 0.5441 - val_accuracy: 0.7448\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8281 - val_loss: 0.5441 - val_accuracy: 0.7448\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8281 - val_loss: 0.5442 - val_accuracy: 0.7448\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8264 - val_loss: 0.5442 - val_accuracy: 0.7448\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8264 - val_loss: 0.5443 - val_accuracy: 0.7448\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8264 - val_loss: 0.5443 - val_accuracy: 0.7448\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8264 - val_loss: 0.5444 - val_accuracy: 0.7448\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8281 - val_loss: 0.5444 - val_accuracy: 0.7448\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8281 - val_loss: 0.5444 - val_accuracy: 0.7448\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8264 - val_loss: 0.5444 - val_accuracy: 0.7448\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8264 - val_loss: 0.5444 - val_accuracy: 0.7448\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8281 - val_loss: 0.5444 - val_accuracy: 0.7448\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3989 - accuracy: 0.8264 - val_loss: 0.5445 - val_accuracy: 0.7448\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8299 - val_loss: 0.5445 - val_accuracy: 0.7448\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8264 - val_loss: 0.5447 - val_accuracy: 0.7448\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8281 - val_loss: 0.5447 - val_accuracy: 0.7448\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8299 - val_loss: 0.5447 - val_accuracy: 0.7448\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8299 - val_loss: 0.5446 - val_accuracy: 0.7448\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8299 - val_loss: 0.5446 - val_accuracy: 0.7448\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8281 - val_loss: 0.5446 - val_accuracy: 0.7448\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8299 - val_loss: 0.5446 - val_accuracy: 0.7448\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8299 - val_loss: 0.5447 - val_accuracy: 0.7448\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8281 - val_loss: 0.5447 - val_accuracy: 0.7448\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8281 - val_loss: 0.5447 - val_accuracy: 0.7448\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8281 - val_loss: 0.5448 - val_accuracy: 0.7448\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8281 - val_loss: 0.5450 - val_accuracy: 0.7448\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8281 - val_loss: 0.5449 - val_accuracy: 0.7448\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8299 - val_loss: 0.5449 - val_accuracy: 0.7448\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8281 - val_loss: 0.5449 - val_accuracy: 0.7448\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8299 - val_loss: 0.5449 - val_accuracy: 0.7448\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8299 - val_loss: 0.5450 - val_accuracy: 0.7448\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8281 - val_loss: 0.5451 - val_accuracy: 0.7448\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8316 - val_loss: 0.5450 - val_accuracy: 0.7448\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8299 - val_loss: 0.5450 - val_accuracy: 0.7448\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8281 - val_loss: 0.5451 - val_accuracy: 0.7448\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.8281 - val_loss: 0.5450 - val_accuracy: 0.7448\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8281 - val_loss: 0.5451 - val_accuracy: 0.7448\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8281 - val_loss: 0.5451 - val_accuracy: 0.7448\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8299 - val_loss: 0.5452 - val_accuracy: 0.7448\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8281 - val_loss: 0.5454 - val_accuracy: 0.7448\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8299 - val_loss: 0.5453 - val_accuracy: 0.7448\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3987 - accuracy: 0.8299 - val_loss: 0.5453 - val_accuracy: 0.7448\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8281 - val_loss: 0.5453 - val_accuracy: 0.7448\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3985 - accuracy: 0.8281 - val_loss: 0.5454 - val_accuracy: 0.7448\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8299 - val_loss: 0.5454 - val_accuracy: 0.7448\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8316 - val_loss: 0.5454 - val_accuracy: 0.7448\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8281 - val_loss: 0.5455 - val_accuracy: 0.7448\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8299 - val_loss: 0.5455 - val_accuracy: 0.7448\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3985 - accuracy: 0.8299 - val_loss: 0.5455 - val_accuracy: 0.7448\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3985 - accuracy: 0.8299 - val_loss: 0.5455 - val_accuracy: 0.7448\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3985 - accuracy: 0.8281 - val_loss: 0.5456 - val_accuracy: 0.7448\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8299 - val_loss: 0.5456 - val_accuracy: 0.7448\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8281 - val_loss: 0.5457 - val_accuracy: 0.7448\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8299 - val_loss: 0.5458 - val_accuracy: 0.7448\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8299 - val_loss: 0.5459 - val_accuracy: 0.7448\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8281 - val_loss: 0.5459 - val_accuracy: 0.7448\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8281 - val_loss: 0.5459 - val_accuracy: 0.7448\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8281 - val_loss: 0.5460 - val_accuracy: 0.7448\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8316 - val_loss: 0.5460 - val_accuracy: 0.7448\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8299 - val_loss: 0.5460 - val_accuracy: 0.7448\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8299 - val_loss: 0.5462 - val_accuracy: 0.7448\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8299 - val_loss: 0.5461 - val_accuracy: 0.7448\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8299 - val_loss: 0.5461 - val_accuracy: 0.7448\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8281 - val_loss: 0.5461 - val_accuracy: 0.7448\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8316 - val_loss: 0.5462 - val_accuracy: 0.7448\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8316 - val_loss: 0.5461 - val_accuracy: 0.7448\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8299 - val_loss: 0.5463 - val_accuracy: 0.7448\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8316 - val_loss: 0.5463 - val_accuracy: 0.7448\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8316 - val_loss: 0.5463 - val_accuracy: 0.7448\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8299 - val_loss: 0.5464 - val_accuracy: 0.7448\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8333 - val_loss: 0.5463 - val_accuracy: 0.7448\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8316 - val_loss: 0.5463 - val_accuracy: 0.7448\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8316 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8316 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8316 - val_loss: 0.5464 - val_accuracy: 0.7448\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8351 - val_loss: 0.5464 - val_accuracy: 0.7448\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8299 - val_loss: 0.5464 - val_accuracy: 0.7448\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8281 - val_loss: 0.5464 - val_accuracy: 0.7448\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8299 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8299 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8316 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8316 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8281 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8316 - val_loss: 0.5466 - val_accuracy: 0.7448\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8299 - val_loss: 0.5467 - val_accuracy: 0.7448\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8316 - val_loss: 0.5468 - val_accuracy: 0.7448\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8299 - val_loss: 0.5468 - val_accuracy: 0.7448\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8316 - val_loss: 0.5469 - val_accuracy: 0.7448\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8333 - val_loss: 0.5469 - val_accuracy: 0.7448\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8316 - val_loss: 0.5470 - val_accuracy: 0.7448\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8299 - val_loss: 0.5470 - val_accuracy: 0.7448\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8316 - val_loss: 0.5470 - val_accuracy: 0.7448\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8316 - val_loss: 0.5470 - val_accuracy: 0.7448\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8316 - val_loss: 0.5470 - val_accuracy: 0.7448\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8316 - val_loss: 0.5470 - val_accuracy: 0.7448\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8299 - val_loss: 0.5471 - val_accuracy: 0.7448\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8316 - val_loss: 0.5471 - val_accuracy: 0.7448\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8299 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8316 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8316 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8299 - val_loss: 0.5473 - val_accuracy: 0.7448\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8316 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8316 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8333 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8299 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8316 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8316 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8316 - val_loss: 0.5475 - val_accuracy: 0.7448\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8299 - val_loss: 0.5477 - val_accuracy: 0.7448\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8316 - val_loss: 0.5478 - val_accuracy: 0.7448\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8333 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8333 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8316 - val_loss: 0.5477 - val_accuracy: 0.7448\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8316 - val_loss: 0.5478 - val_accuracy: 0.7448\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8316 - val_loss: 0.5477 - val_accuracy: 0.7448\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8316 - val_loss: 0.5478 - val_accuracy: 0.7448\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8316 - val_loss: 0.5479 - val_accuracy: 0.7448\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8299 - val_loss: 0.5480 - val_accuracy: 0.7448\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8316 - val_loss: 0.5481 - val_accuracy: 0.7448\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8333 - val_loss: 0.5481 - val_accuracy: 0.7448\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8316 - val_loss: 0.5480 - val_accuracy: 0.7448\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8299 - val_loss: 0.5481 - val_accuracy: 0.7448\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8333 - val_loss: 0.5481 - val_accuracy: 0.7448\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8316 - val_loss: 0.5482 - val_accuracy: 0.7448\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8333 - val_loss: 0.5482 - val_accuracy: 0.7448\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8316 - val_loss: 0.5482 - val_accuracy: 0.7448\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8316 - val_loss: 0.5482 - val_accuracy: 0.7448\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8299 - val_loss: 0.5482 - val_accuracy: 0.7448\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8333 - val_loss: 0.5482 - val_accuracy: 0.7396\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8316 - val_loss: 0.5483 - val_accuracy: 0.7396\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8316 - val_loss: 0.5483 - val_accuracy: 0.7448\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8316 - val_loss: 0.5484 - val_accuracy: 0.7448\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8333 - val_loss: 0.5485 - val_accuracy: 0.7448\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8316 - val_loss: 0.5485 - val_accuracy: 0.7448\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8316 - val_loss: 0.5485 - val_accuracy: 0.7448\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8316 - val_loss: 0.5486 - val_accuracy: 0.7448\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8333 - val_loss: 0.5486 - val_accuracy: 0.7448\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8316 - val_loss: 0.5486 - val_accuracy: 0.7448\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8333 - val_loss: 0.5487 - val_accuracy: 0.7448\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8316 - val_loss: 0.5487 - val_accuracy: 0.7448\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8316 - val_loss: 0.5488 - val_accuracy: 0.7396\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8316 - val_loss: 0.5488 - val_accuracy: 0.7396\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8316 - val_loss: 0.5488 - val_accuracy: 0.7396\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8316 - val_loss: 0.5489 - val_accuracy: 0.7396\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8333 - val_loss: 0.5490 - val_accuracy: 0.7396\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8333 - val_loss: 0.5491 - val_accuracy: 0.7396\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8316 - val_loss: 0.5490 - val_accuracy: 0.7396\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8316 - val_loss: 0.5491 - val_accuracy: 0.7448\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8333 - val_loss: 0.5490 - val_accuracy: 0.7448\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8316 - val_loss: 0.5491 - val_accuracy: 0.7396\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8333 - val_loss: 0.5490 - val_accuracy: 0.7448\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8333 - val_loss: 0.5491 - val_accuracy: 0.7396\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8333 - val_loss: 0.5491 - val_accuracy: 0.7396\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8333 - val_loss: 0.5492 - val_accuracy: 0.7396\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8316 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8333 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8299 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8333 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8299 - val_loss: 0.5492 - val_accuracy: 0.7396\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8316 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3971 - accuracy: 0.8333 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8333 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3971 - accuracy: 0.8316 - val_loss: 0.5495 - val_accuracy: 0.7396\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8299 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8333 - val_loss: 0.5495 - val_accuracy: 0.7396\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8316 - val_loss: 0.5495 - val_accuracy: 0.7396\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8333 - val_loss: 0.5495 - val_accuracy: 0.7396\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8316 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3970 - accuracy: 0.8333 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8316 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8333 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8333 - val_loss: 0.5497 - val_accuracy: 0.7396\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8333 - val_loss: 0.5498 - val_accuracy: 0.7396\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8316 - val_loss: 0.5498 - val_accuracy: 0.7396\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8316 - val_loss: 0.5498 - val_accuracy: 0.7396\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3970 - accuracy: 0.8316 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8333 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8333 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8333 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8351 - val_loss: 0.5500 - val_accuracy: 0.7396\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8333 - val_loss: 0.5498 - val_accuracy: 0.7396\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8333 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8316 - val_loss: 0.5501 - val_accuracy: 0.7396\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8333 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8333 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8333 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8333 - val_loss: 0.5502 - val_accuracy: 0.7396\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8316 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3968 - accuracy: 0.8333 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8333 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8333 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3969 - accuracy: 0.8351 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8351 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8333 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3968 - accuracy: 0.8316 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8333 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8333 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8333 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8333 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8333 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8333 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3967 - accuracy: 0.8333 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8333 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8333 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8333 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8316 - val_loss: 0.5509 - val_accuracy: 0.7396\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8333 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8333 - val_loss: 0.5509 - val_accuracy: 0.7396\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8316 - val_loss: 0.5510 - val_accuracy: 0.7396\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8333 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8333 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8351 - val_loss: 0.5512 - val_accuracy: 0.7396\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8333 - val_loss: 0.5512 - val_accuracy: 0.7396\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8333 - val_loss: 0.5512 - val_accuracy: 0.7396\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8333 - val_loss: 0.5513 - val_accuracy: 0.7396\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8316 - val_loss: 0.5514 - val_accuracy: 0.7396\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8333 - val_loss: 0.5514 - val_accuracy: 0.7396\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8351 - val_loss: 0.5516 - val_accuracy: 0.7396\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8333 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8333 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8333 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8333 - val_loss: 0.5516 - val_accuracy: 0.7396\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8333 - val_loss: 0.5516 - val_accuracy: 0.7396\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8333 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8316 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8316 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8351 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8333 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8316 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8299 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8316 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8333 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8316 - val_loss: 0.5520 - val_accuracy: 0.7396\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8316 - val_loss: 0.5520 - val_accuracy: 0.7396\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8316 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8299 - val_loss: 0.5520 - val_accuracy: 0.7396\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8316 - val_loss: 0.5520 - val_accuracy: 0.7396\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8299 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8333 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8316 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8316 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8316 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8333 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8316 - val_loss: 0.5523 - val_accuracy: 0.7396\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8299 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8316 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8316 - val_loss: 0.5525 - val_accuracy: 0.7396\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8316 - val_loss: 0.5525 - val_accuracy: 0.7396\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8299 - val_loss: 0.5525 - val_accuracy: 0.7396\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8316 - val_loss: 0.5525 - val_accuracy: 0.7396\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8316 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8299 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8299 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8299 - val_loss: 0.5525 - val_accuracy: 0.7396\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8299 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8316 - val_loss: 0.5525 - val_accuracy: 0.7396\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8316 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8333 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8316 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8299 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8299 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8316 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8316 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8299 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8299 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8316 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8333 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8316 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8333 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8316 - val_loss: 0.5530 - val_accuracy: 0.7396\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8316 - val_loss: 0.5530 - val_accuracy: 0.7396\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8316 - val_loss: 0.5530 - val_accuracy: 0.7396\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8316 - val_loss: 0.5531 - val_accuracy: 0.7396\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8316 - val_loss: 0.5531 - val_accuracy: 0.7396\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8316 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8351 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8299 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8316 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8316 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8351 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8316 - val_loss: 0.5533 - val_accuracy: 0.7396\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8316 - val_loss: 0.5533 - val_accuracy: 0.7396\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8316 - val_loss: 0.5534 - val_accuracy: 0.7396\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8333 - val_loss: 0.5534 - val_accuracy: 0.7396\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8299 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8299 - val_loss: 0.5536 - val_accuracy: 0.7396\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8316 - val_loss: 0.5536 - val_accuracy: 0.7396\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8333 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8316 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8316 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8316 - val_loss: 0.5538 - val_accuracy: 0.7396\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8351 - val_loss: 0.5538 - val_accuracy: 0.7396\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8316 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8299 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8333 - val_loss: 0.5538 - val_accuracy: 0.7396\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8299 - val_loss: 0.5539 - val_accuracy: 0.7396\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8316 - val_loss: 0.5539 - val_accuracy: 0.7396\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8316 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8299 - val_loss: 0.5539 - val_accuracy: 0.7396\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8316 - val_loss: 0.5539 - val_accuracy: 0.7396\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8351 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8333 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8316 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8316 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8333 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8316 - val_loss: 0.5540 - val_accuracy: 0.7396\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8351 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8316 - val_loss: 0.5542 - val_accuracy: 0.7396\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3957 - accuracy: 0.8333 - val_loss: 0.5542 - val_accuracy: 0.7396\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8316 - val_loss: 0.5542 - val_accuracy: 0.7396\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8316 - val_loss: 0.5542 - val_accuracy: 0.7396\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8351 - val_loss: 0.5543 - val_accuracy: 0.7396\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8351 - val_loss: 0.5543 - val_accuracy: 0.7396\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8333 - val_loss: 0.5543 - val_accuracy: 0.7396\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3956 - accuracy: 0.8351 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3957 - accuracy: 0.8299 - val_loss: 0.5545 - val_accuracy: 0.7396\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8333 - val_loss: 0.5545 - val_accuracy: 0.7396\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8333 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.8316 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3955 - accuracy: 0.8351 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.5549 - val_accuracy: 0.7396\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8351 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.5549 - val_accuracy: 0.7396\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8316 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8333 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8351 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.5549 - val_accuracy: 0.7396\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8316 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8333 - val_loss: 0.5549 - val_accuracy: 0.7396\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3954 - accuracy: 0.8333 - val_loss: 0.5549 - val_accuracy: 0.7396\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8351 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8351 - val_loss: 0.5551 - val_accuracy: 0.7396\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8351 - val_loss: 0.5553 - val_accuracy: 0.7396\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8333 - val_loss: 0.5552 - val_accuracy: 0.7396\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8351 - val_loss: 0.5552 - val_accuracy: 0.7396\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8351 - val_loss: 0.5553 - val_accuracy: 0.7396\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3953 - accuracy: 0.8299 - val_loss: 0.5554 - val_accuracy: 0.7396\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8333 - val_loss: 0.5553 - val_accuracy: 0.7396\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8351 - val_loss: 0.5553 - val_accuracy: 0.7396\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8316 - val_loss: 0.5552 - val_accuracy: 0.7396\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8316 - val_loss: 0.5553 - val_accuracy: 0.7396\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8333 - val_loss: 0.5554 - val_accuracy: 0.7396\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8333 - val_loss: 0.5555 - val_accuracy: 0.7396\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8333 - val_loss: 0.5555 - val_accuracy: 0.7396\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8316 - val_loss: 0.5556 - val_accuracy: 0.7396\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8333 - val_loss: 0.5556 - val_accuracy: 0.7396\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8316 - val_loss: 0.5554 - val_accuracy: 0.7396\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8333 - val_loss: 0.5556 - val_accuracy: 0.7396\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8351 - val_loss: 0.5556 - val_accuracy: 0.7396\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8333 - val_loss: 0.5559 - val_accuracy: 0.7396\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8333 - val_loss: 0.5558 - val_accuracy: 0.7448\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8351 - val_loss: 0.5558 - val_accuracy: 0.7396\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8351 - val_loss: 0.5559 - val_accuracy: 0.7396\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8333 - val_loss: 0.5559 - val_accuracy: 0.7396\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8333 - val_loss: 0.5559 - val_accuracy: 0.7396\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8351 - val_loss: 0.5559 - val_accuracy: 0.7396\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3951 - accuracy: 0.8316 - val_loss: 0.5560 - val_accuracy: 0.7396\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8333 - val_loss: 0.5559 - val_accuracy: 0.7396\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8333 - val_loss: 0.5560 - val_accuracy: 0.7448\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8351 - val_loss: 0.5560 - val_accuracy: 0.7448\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8333 - val_loss: 0.5560 - val_accuracy: 0.7448\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8351 - val_loss: 0.5562 - val_accuracy: 0.7448\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8351 - val_loss: 0.5561 - val_accuracy: 0.7396\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8333 - val_loss: 0.5560 - val_accuracy: 0.7448\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.8333 - val_loss: 0.5560 - val_accuracy: 0.7448\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8333 - val_loss: 0.5559 - val_accuracy: 0.7448\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8351 - val_loss: 0.5561 - val_accuracy: 0.7448\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8351 - val_loss: 0.5562 - val_accuracy: 0.7448\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8351 - val_loss: 0.5564 - val_accuracy: 0.7448\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8333 - val_loss: 0.5563 - val_accuracy: 0.7448\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8351 - val_loss: 0.5564 - val_accuracy: 0.7448\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8351 - val_loss: 0.5565 - val_accuracy: 0.7448\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8316 - val_loss: 0.5565 - val_accuracy: 0.7448\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8351 - val_loss: 0.5566 - val_accuracy: 0.7448\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8351 - val_loss: 0.5566 - val_accuracy: 0.7500\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8351 - val_loss: 0.5567 - val_accuracy: 0.7448\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8316 - val_loss: 0.5567 - val_accuracy: 0.7448\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8351 - val_loss: 0.5567 - val_accuracy: 0.7500\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8351 - val_loss: 0.5566 - val_accuracy: 0.7448\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8316 - val_loss: 0.5568 - val_accuracy: 0.7448\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8333 - val_loss: 0.5568 - val_accuracy: 0.7448\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8316 - val_loss: 0.5569 - val_accuracy: 0.7448\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8333 - val_loss: 0.5569 - val_accuracy: 0.7448\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8351 - val_loss: 0.5570 - val_accuracy: 0.7448\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8385 - val_loss: 0.5569 - val_accuracy: 0.7448\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8333 - val_loss: 0.5569 - val_accuracy: 0.7396\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8333 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8333 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8333 - val_loss: 0.5570 - val_accuracy: 0.7448\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8333 - val_loss: 0.5571 - val_accuracy: 0.7396\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3948 - accuracy: 0.8299 - val_loss: 0.5570 - val_accuracy: 0.7448\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3948 - accuracy: 0.8351 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3948 - accuracy: 0.8333 - val_loss: 0.5570 - val_accuracy: 0.7448\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3948 - accuracy: 0.8316 - val_loss: 0.5571 - val_accuracy: 0.7448\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3947 - accuracy: 0.8333 - val_loss: 0.5572 - val_accuracy: 0.7448\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3947 - accuracy: 0.8368 - val_loss: 0.5572 - val_accuracy: 0.7448\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3947 - accuracy: 0.8333 - val_loss: 0.5572 - val_accuracy: 0.7448\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3948 - accuracy: 0.8333 - val_loss: 0.5572 - val_accuracy: 0.7448\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3949 - accuracy: 0.8385 - val_loss: 0.5572 - val_accuracy: 0.7448\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3946 - accuracy: 0.8368 - val_loss: 0.5574 - val_accuracy: 0.7448\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3947 - accuracy: 0.8333 - val_loss: 0.5574 - val_accuracy: 0.7448\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3947 - accuracy: 0.8351 - val_loss: 0.5573 - val_accuracy: 0.7448\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3948 - accuracy: 0.8299 - val_loss: 0.5575 - val_accuracy: 0.7448\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3946 - accuracy: 0.8368 - val_loss: 0.5576 - val_accuracy: 0.7448\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3946 - accuracy: 0.8333 - val_loss: 0.5576 - val_accuracy: 0.7448\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3946 - accuracy: 0.8333 - val_loss: 0.5576 - val_accuracy: 0.7448\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3946 - accuracy: 0.8351 - val_loss: 0.5576 - val_accuracy: 0.7448\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3945 - accuracy: 0.8351 - val_loss: 0.5577 - val_accuracy: 0.7396\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3946 - accuracy: 0.8368 - val_loss: 0.5577 - val_accuracy: 0.7396\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3946 - accuracy: 0.8368 - val_loss: 0.5578 - val_accuracy: 0.7396\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3947 - accuracy: 0.8368 - val_loss: 0.5578 - val_accuracy: 0.7396\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3946 - accuracy: 0.8368 - val_loss: 0.5579 - val_accuracy: 0.7396\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3945 - accuracy: 0.8333 - val_loss: 0.5580 - val_accuracy: 0.7396\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3945 - accuracy: 0.8351 - val_loss: 0.5579 - val_accuracy: 0.7396\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3944 - accuracy: 0.8368 - val_loss: 0.5580 - val_accuracy: 0.7396\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3945 - accuracy: 0.8333 - val_loss: 0.5580 - val_accuracy: 0.7396\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8385 - val_loss: 0.5580 - val_accuracy: 0.7396\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3945 - accuracy: 0.8333 - val_loss: 0.5581 - val_accuracy: 0.7396\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8351 - val_loss: 0.5582 - val_accuracy: 0.7448\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8368 - val_loss: 0.5583 - val_accuracy: 0.7396\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8368 - val_loss: 0.5583 - val_accuracy: 0.7448\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8368 - val_loss: 0.5584 - val_accuracy: 0.7448\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8368 - val_loss: 0.5584 - val_accuracy: 0.7448\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8351 - val_loss: 0.5584 - val_accuracy: 0.7396\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3944 - accuracy: 0.8351 - val_loss: 0.5584 - val_accuracy: 0.7396\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3943 - accuracy: 0.8333 - val_loss: 0.5585 - val_accuracy: 0.7396\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3942 - accuracy: 0.8385 - val_loss: 0.5584 - val_accuracy: 0.7396\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8351 - val_loss: 0.5585 - val_accuracy: 0.7396\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8351 - val_loss: 0.5585 - val_accuracy: 0.7396\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8385 - val_loss: 0.5585 - val_accuracy: 0.7396\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8333 - val_loss: 0.5586 - val_accuracy: 0.7396\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8351 - val_loss: 0.5586 - val_accuracy: 0.7448\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3943 - accuracy: 0.8333 - val_loss: 0.5586 - val_accuracy: 0.7396\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8316 - val_loss: 0.5587 - val_accuracy: 0.7448\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3942 - accuracy: 0.8333 - val_loss: 0.5588 - val_accuracy: 0.7396\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3942 - accuracy: 0.8351 - val_loss: 0.5588 - val_accuracy: 0.7448\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3942 - accuracy: 0.8351 - val_loss: 0.5588 - val_accuracy: 0.7448\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3942 - accuracy: 0.8385 - val_loss: 0.5587 - val_accuracy: 0.7448\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8368 - val_loss: 0.5587 - val_accuracy: 0.7396\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8368 - val_loss: 0.5587 - val_accuracy: 0.7448\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8351 - val_loss: 0.5587 - val_accuracy: 0.7396\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3941 - accuracy: 0.8351 - val_loss: 0.5589 - val_accuracy: 0.7448\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8403 - val_loss: 0.5589 - val_accuracy: 0.7448\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8368 - val_loss: 0.5590 - val_accuracy: 0.7500\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8368 - val_loss: 0.5591 - val_accuracy: 0.7448\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8368 - val_loss: 0.5591 - val_accuracy: 0.7448\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.8368 - val_loss: 0.5592 - val_accuracy: 0.7396\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8403 - val_loss: 0.5593 - val_accuracy: 0.7396\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8368 - val_loss: 0.5592 - val_accuracy: 0.7396\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8385 - val_loss: 0.5593 - val_accuracy: 0.7396\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8385 - val_loss: 0.5592 - val_accuracy: 0.7448\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8385 - val_loss: 0.5592 - val_accuracy: 0.7448\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8403 - val_loss: 0.5593 - val_accuracy: 0.7448\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8368 - val_loss: 0.5593 - val_accuracy: 0.7448\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8368 - val_loss: 0.5593 - val_accuracy: 0.7448\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8385 - val_loss: 0.5593 - val_accuracy: 0.7448\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8368 - val_loss: 0.5595 - val_accuracy: 0.7448\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8368 - val_loss: 0.5595 - val_accuracy: 0.7448\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8368 - val_loss: 0.5594 - val_accuracy: 0.7448\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8385 - val_loss: 0.5596 - val_accuracy: 0.7448\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8368 - val_loss: 0.5596 - val_accuracy: 0.7448\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8351 - val_loss: 0.5596 - val_accuracy: 0.7448\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8368 - val_loss: 0.5596 - val_accuracy: 0.7448\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8368 - val_loss: 0.5597 - val_accuracy: 0.7448\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8368 - val_loss: 0.5598 - val_accuracy: 0.7448\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8368 - val_loss: 0.5598 - val_accuracy: 0.7448\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8385 - val_loss: 0.5600 - val_accuracy: 0.7448\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8368 - val_loss: 0.5601 - val_accuracy: 0.7448\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8385 - val_loss: 0.5601 - val_accuracy: 0.7448\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8351 - val_loss: 0.5600 - val_accuracy: 0.7448\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8351 - val_loss: 0.5600 - val_accuracy: 0.7448\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8351 - val_loss: 0.5601 - val_accuracy: 0.7448\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8385 - val_loss: 0.5601 - val_accuracy: 0.7448\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8351 - val_loss: 0.5601 - val_accuracy: 0.7500\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8351 - val_loss: 0.5601 - val_accuracy: 0.7500\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8368 - val_loss: 0.5602 - val_accuracy: 0.7500\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8368 - val_loss: 0.5603 - val_accuracy: 0.7500\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8368 - val_loss: 0.5603 - val_accuracy: 0.7500\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8351 - val_loss: 0.5602 - val_accuracy: 0.7448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_2 = (model2.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
        "y_pred_prob_nn_2 = model2.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsgM5fjsdDht",
        "outputId": "2532dcd3-d56b-48e4-cb1a-d278a19bb9f3"
      },
      "id": "IsgM5fjsdDht",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_2[:10]"
      ],
      "metadata": {
        "id": "Qx2pe2ULTC_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d58597f8-1403-4579-81a8-c3030c6d1fe5"
      },
      "id": "Qx2pe2ULTC_a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_2[:10]"
      ],
      "metadata": {
        "id": "qJtu6bFtTC8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e134a5-7f76-4775-d37e-437471426d29"
      },
      "id": "qJtu6bFtTC8k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4210953 ],\n",
              "       [0.32313898],\n",
              "       [0.47941372],\n",
              "       [0.48243412],\n",
              "       [0.5       ],\n",
              "       [0.38059798],\n",
              "       [0.5       ],\n",
              "       [0.4251052 ],\n",
              "       [0.40425262],\n",
              "       [0.5       ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_hist2.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyGWK7BgedLq",
        "outputId": "e58cc169-72c4-410a-9813-d3aecd7735ce"
      },
      "id": "YyGWK7BgedLq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "nf4KA7VcedJJ",
        "outputId": "d52fe252-c3b7-41eb-dd92-0871926038b7"
      },
      "id": "nf4KA7VcedJJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7d12e94f7070>"
            ]
          },
          "metadata": {},
          "execution_count": 180
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intimate-factory",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### Conclusion\n",
        "\n",
        "In conclusion, this lesson is about from using the previous lesson about Neural Network and applying it on a different model and layer to showcase the graphical result. This is similar from prediction regression but the difference here is the iteration of epochs involved here in order to get the data we need and showcase it, which sometimes has some presentation errors if not properly input the right code for it. The graph we use here is about predicting training loss and validation loss that decreases, to know that the model of prediction is in the right classification."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}